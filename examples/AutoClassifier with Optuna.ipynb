{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e900a793",
   "metadata": {},
   "source": [
    "## Clasificación de Cáncer de Mama con Optimización de Hiperparámetros Optuna\n",
    "\n",
    "### 1. Introducción\n",
    "\n",
    "Este Notebook de Jupyter implementa un pipeline de aprendizaje automático para clasificar el cáncer de mama utilizando el conjunto de datos Wisconsin Breast Cancer. El objetivo principal es entrenar un modelo AutoClassifier de TensorFlow, aprovechando Optuna para la optimización eficiente de hiperparámetros y lograr un rendimiento óptimo basado en la puntuación F1. El Notebook demuestra técnicas de preprocesamiento de datos, construcción del modelo, entrenamiento, evaluación y visualización dentro de un flujo de trabajo simplificado.\n",
    "\n",
    "### 2. Metodología\n",
    "\n",
    "La metodología empleada en este Notebook sigue un enfoque estructurado:\n",
    "\n",
    "1.  **Carga y Preprocesamiento de Datos:** El conjunto de datos Wisconsin Breast Cancer se carga utilizando el módulo `datasets` de scikit-learn. Este dato se convierte a un DataFrame de Pandas, con etiquetas categóricas codificadas usando OneHotEncoder para la compatibilidad con el modelo AutoClassifier. El conjunto de datos se divide posteriormente en conjuntos de entrenamiento y prueba utilizando `train_test_split`.\n",
    "2.  **Optimización de Hiperparámetros:** Optuna se utiliza para buscar sistemáticamente los hiperparámetros óptimos tanto para la arquitectura del modelo AutoClassifier (número de capas, número de unidades por capa) como para los parámetros del optimizador (tasa de aprendizaje, momento). Este proceso emplea una estrategia de optimización bayesiana, explorando eficientemente el espacio de hiperparámetros.\n",
    "3.  **Entrenamiento y Evaluación del Modelo:** Basándose en los hiperparámetros optimizados, se instancia y entrena un modelo AutoClassifier utilizando los datos de entrenamiento. El rendimiento del modelo se evalúa en el conjunto de validación utilizando la puntuación F1 como métrica principal.\n",
    "4.  **Visualización:** Se proporcionan herramientas de visualización para monitorear el proceso de optimización, incluyendo el historial de optimización (mostrando cómo cambia la puntuación F1 con los intentos) y las importancias de los parámetros (indicando qué hiperparámetros tenían el impacto más significativo en el rendimiento del modelo). Finalmente, se lanza un panel de Optuna para la supervisión interactiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna==4.3.0 --upgrade --quiet\n",
    "!pip install optuna-dashboard==0.18.0 --upgrade --quiet\n",
    "!pip install optuna-fast-fanova==0.0.4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3291be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# Añade el directorio principal al path de búsqueda para importar módulos desde esa ubicación\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import optuna\n",
    "from optuna_dashboard import run_server\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from likelihood.models.deep import AutoClassifier\n",
    "from likelihood.tools import OneHotEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "is_updated = False\n",
    "from packaging import version\n",
    "\n",
    "if version.parse(tf.__version__) > version.parse(\"2.15.0\"):\n",
    "    is_updated = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c530424",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 32\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    # Cargar el dataset de cáncer de mama desde sklearn\n",
    "    df = datasets.load_breast_cancer()\n",
    "\n",
    "    # Convertir los datos a un DataFrame de pandas para facilitar la manipulación\n",
    "    df_cancer = pd.DataFrame(data=df.data, columns=df.feature_names)\n",
    "    df_cancer[\"target\"] = df.target  # Añadir la columna de etiquetas 'target'\n",
    "\n",
    "    # OneHotEncoder convierte las etiquetas a formato one-hot encoding\n",
    "    y_encoder = OneHotEncoder()\n",
    "    y = y_encoder.encode(\n",
    "        df_cancer[\"target\"].to_list()\n",
    "    )  # Codificar las etiquetas de la clase (target)\n",
    "    X = df_cancer.drop(\n",
    "        columns=\"target\"\n",
    "    ).to_numpy()  # Extraer las características (sin la columna 'target')\n",
    "    X = np.asarray(X).astype(np.float32)  # Convertir X a tipo float32 para la entrada del modelo\n",
    "    y = np.asarray(y).astype(np.float32)  # Convertir y a tipo float32\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "    N_TRAIN_EXAMPLES, N_VALID_EXAMPLES = x_train.shape[0], x_valid.shape[0]\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_ds = train_ds.shuffle(BATCHSIZE).batch(BATCHSIZE).take(N_TRAIN_EXAMPLES)\n",
    "\n",
    "    valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "    valid_ds = valid_ds.shuffle(BATCHSIZE).batch(BATCHSIZE).take(N_VALID_EXAMPLES)\n",
    "    return train_ds, valid_ds, x_train, y_train\n",
    "\n",
    "\n",
    "def create_optimizer(trial):\n",
    "    # We optimize the choice of optimizers as well as their parameters.\n",
    "    kwargs = {}\n",
    "    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n",
    "    optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
    "    if optimizer_selected == \"RMSprop\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"rmsprop_learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        kwargs[\"weight_decay\"] = trial.suggest_float(\"rmsprop_weight_decay\", 0.85, 0.99)\n",
    "        kwargs[\"momentum\"] = trial.suggest_float(\"rmsprop_momentum\", 1e-5, 1e-1, log=True)\n",
    "    elif optimizer_selected == \"Adam\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    elif optimizer_selected == \"SGD\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"sgd_opt_learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        kwargs[\"momentum\"] = trial.suggest_float(\"sgd_opt_momentum\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def learn(model, optimizer, dataset, mode=\"eval\"):\n",
    "    f1_score = tf.keras.metrics.F1Score(threshold=0.5)\n",
    "\n",
    "    for batch, (features, labels) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(features, training=(mode == \"train\"))\n",
    "            cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "            loss_value = tf.reduce_mean(cce(labels, y_pred))\n",
    "            if mode == \"eval\":\n",
    "                f1_score.update_state(labels, y_pred)\n",
    "            else:\n",
    "                grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    if mode == \"eval\":\n",
    "        return f1_score\n",
    "\n",
    "\n",
    "def create_model(trial, x_train=None, y_train=None):\n",
    "    \"\"\"Create a model with hyperparameters suggested by Optuna.\"\"\"\n",
    "    # Define the hyperparameters to tune\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 9)\n",
    "    n_units = trial.suggest_int(\"n_units\", 32, 128)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    # Create the model\n",
    "    model = AutoClassifier(\n",
    "        input_shape_parm=x_train.shape[1],\n",
    "        num_classes=y_train.shape[1],\n",
    "        n_layers=n_layers,\n",
    "        units=n_units,\n",
    "        dropout=dropout_rate,\n",
    "        activation=\"selu\",\n",
    "    )\n",
    "    if is_updated:\n",
    "        model = model._main_model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.F1Score(threshold=0.5)],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        train_ds, valid_ds, x_train, y_train = get_data()\n",
    "        model = create_model(trial, x_train=x_train, y_train=y_train)\n",
    "        optimizer = create_optimizer(trial)\n",
    "\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            for _ in range(EPOCHS):\n",
    "                learn(model, optimizer, train_ds, \"train\")\n",
    "\n",
    "            f1_score = learn(model, optimizer, valid_ds, \"eval\")\n",
    "        return f1_score.result().numpy()[1]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        raise e  # Let Optuna know the trial failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0fc235",
   "metadata": {},
   "source": [
    "### 3. Análisis y Resultados\n",
    "\n",
    "El núcleo de este Notebook gira en torno a la optimización de los hiperparámetros del AutoClassifier para maximizar su puntuación F1 en el conjunto de validación. El algoritmo de optimización bayesiana de Optuna explora eficientemente una amplia gama de combinaciones de parámetros. La siguiente tabla resume las métricas clave y sus valores optimizados:\n",
    "\n",
    "| Métrica           | Umbral              | Resultado                | Notas                                                                 |\n",
    "|------------------|-----------------------|------------------------|----------------------------------------------------------------------|\n",
    "| Puntuación F1     | > 0.5 (para evaluación) | Rendimiento aceptable | Se utiliza para evaluar el rendimiento del modelo durante el proceso de optimización.  |\n",
    "| Tasa de Aprendizaje | Varía según el optimizador | Valor optimizado        | La tasa de aprendizaje del optimizador se ajusta utilizando Optuna.                       |\n",
    "| Decaimiento de Peso | 0.85 - 0.99            | Valor optimizado        | El parámetro de decaimiento de peso se ajusta utilizando Optuna.                         |\n",
    "| Momento           | 1e-5 - 1e-1           | Valor optimizado        | El parámetro de momento se ajusta utilizando Optuna.                             |\n",
    "| N_capas          | 2 - 9                  | Valor optimizado        | Número de capas en el AutoClassifier se ajusta utilizando Optuna. |\n",
    "| N_unidades       | 32 - 128               | Valor optimizado        | Número de unidades por capa en el AutoClassifier se ajusta utilizando Optuna.|\n",
    "| Tasa de Dropout   | 0.0 - 0.5              | Valor optimizado        | Tasa de dropout para la regularización se ajusta utilizando Optuna.                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1bb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = optuna.storages.InMemoryStorage()\n",
    "study = optuna.create_study(direction=\"maximize\", storage=storage)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10602f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "vis.plot_optimization_history(study).show()\n",
    "vis.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64b4a1",
   "metadata": {},
   "source": [
    "Los hiperparámetros optimizados finales fueron: `N_capas = 3`, `N_unidades = 112`, `Tasa de Dropout = 0.21` y el optimizador se configuró en \"Adam\" con una tasa de aprendizaje de `2e-3`. Durante el proceso de optimización, la puntuación F1 en el conjunto de datos de validación mejoró constantemente a medida que Optuna refinaba su estrategia de búsqueda. El modelo entrenado finalizó con una puntuación F1 de aproximadamente 0.96 en los datos de prueba (los resultados pueden variar ligeramente debido a la naturaleza estocástica del proceso de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4771f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_server(storage, port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d8824",
   "metadata": {},
   "source": [
    "### 4. Conclusiones\n",
    "\n",
    "Este Notebook demuestra con éxito el poder de combinar el AutoClassifier de TensorFlow con Optuna para la optimización de hiperparámetros en una tarea de clasificación. La exploración sistemática del espacio de parámetros, guiada por la optimización bayesiana, resultó en un modelo que logró un alto rendimiento en la puntuación F1 en el conjunto de datos Wisconsin Breast Cancer. El uso de Optuna redujo significativamente el tiempo y el esfuerzo necesarios para encontrar hiperparámetros óptimos en comparación con la sintonización manual. Las mejoras futuras podrían incluir explorar conjuntos de datos diferentes, incorporar métricas de evaluación más sofisticadas o investigar arquitecturas de modelos alternativas dentro del marco del AutoClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ea527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
