<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>likelihood.models.deep.predictor API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>likelihood.models.deep.predictor</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="likelihood.models.deep.predictor.GetInsights"><code class="flex name class">
<span>class <span class="ident">GetInsights</span></span>
<span>(</span><span>model:¬†<a title="likelihood.models.deep.autoencoders.AutoClassifier" href="autoencoders.html#likelihood.models.deep.autoencoders.AutoClassifier">AutoClassifier</a>,<br>inputs:¬†numpy.ndarray)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GetInsights:
    &#34;&#34;&#34;
    A class to analyze the output of a neural network model, including visualizations
    of the weights, t-SNE representation, and feature statistics.

    Parameters
    ----------
    model : `AutoClassifier`
        The trained model to analyze.
    inputs : `np.ndarray`
        The input data for analysis.
    &#34;&#34;&#34;

    def __init__(self, model: AutoClassifier, inputs: np.ndarray) -&gt; None:
        &#34;&#34;&#34;
        Initializes the GetInsights class.

        Parameters
        ----------
        model : `AutoClassifier`
            The trained model to analyze.
        inputs : `np.ndarray`
            The input data for analysis.
        &#34;&#34;&#34;
        self.inputs = inputs
        self.model = model

        self.encoder_layer = (
            self.model.encoder.layers[1]
            if isinstance(self.model.encoder.layers[0], InputLayer)
            else self.model.encoder.layers[0]
        )
        self.decoder_layer = self.model.decoder.layers[0]

        self.encoder_weights = self.encoder_layer.get_weights()[0]
        self.decoder_weights = self.decoder_layer.get_weights()[0]

        self.sorted_names = self._generate_sorted_color_names()

    def _generate_sorted_color_names(self) -&gt; list:
        &#34;&#34;&#34;
        Generate sorted color names based on their HSV values.

        Parameters
        ----------
        `None`

        Returns
        -------
        `list` : Sorted color names.
        &#34;&#34;&#34;
        colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)
        by_hsv = sorted(
            (tuple(mcolors.rgb_to_hsv(mcolors.to_rgba(color)[:3])), name)
            for name, color in colors.items()
        )
        sorted_names = [name for hsv, name in by_hsv if hsv[1] &gt; 0.4 and hsv[2] &gt;= 0.4]
        random.shuffle(sorted_names)
        return sorted_names

    def render_html_report(
        self,
        frac: float = 0.2,
        top_k: int = 5,
        threshold_factor: float = 1.0,
        max_rows: int = 5,
        **kwargs,
    ) -&gt; None:
        &#34;&#34;&#34;
        Generate and display an embedded HTML report in a Jupyter Notebook cell.
        &#34;&#34;&#34;
        display(HTML(&#34;&lt;h2 style=&#39;margin-top:20px;&#39;&gt;üìä Predictor Analysis&lt;/h2&gt;&#34;))
        display(
            HTML(
                &#34;&lt;p&gt;This section visualizes how the model predicts the data. &#34;
                &#34;You will see original inputs, reconstructed outputs, and analyses such as t-SNE &#34;
                &#34;that reduce dimensionality to visualize latent space clustering.&lt;/p&gt;&#34;
            )
        )
        stats_df = self.predictor_analyzer(frac=frac, **kwargs)

        display(HTML(&#34;&lt;h2 style=&#39;margin-top:30px;&#39;&gt;üîÅ Encoder-Decoder Graph&lt;/h2&gt;&#34;))
        display(
            HTML(
                &#34;&lt;p&gt;This visualization displays the connections between layers in the encoder and decoder. &#34;
                &#34;Edges with the strongest weights are highlighted to emphasize influential features &#34;
                &#34;in the model&#39;s transformation.&lt;/p&gt;&#34;
            )
        )
        if not self.model.encoder.name.startswith(&#34;vae&#34;):
            self.viz_encoder_decoder_graphs(threshold_factor=threshold_factor, top_k=top_k)

            display(HTML(&#34;&lt;h2 style=&#39;margin-top:30px;&#39;&gt;üß† Classifier Layer Graphs&lt;/h2&gt;&#34;))
            display(
                HTML(
                    &#34;&lt;p&gt;This visualization shows how features propagate through each dense layer in the classifier. &#34;
                    &#34;Only the strongest weighted connections are shown to highlight influential paths through the network.&lt;/p&gt;&#34;
                )
            )
        self.viz_classifier_graphs(threshold_factor=threshold_factor, top_k=top_k)

        display(HTML(&#34;&lt;h2 style=&#39;margin-top:30px;&#39;&gt;üìà Statistical Summary&lt;/h2&gt;&#34;))
        display(
            HTML(
                &#34;&lt;p&gt;This table summarizes feature statistics grouped by predicted classes, &#34;
                &#34;including means, standard deviations, and modes, providing insight into &#34;
                &#34;feature distributions across different classes.&lt;/p&gt;&#34;
            )
        )

        if max_rows is not None and max_rows &gt; 0:
            stats_to_display = stats_df.head(max_rows)
        else:
            stats_to_display = stats_df

        display(
            stats_to_display.style.set_table_attributes(
                &#34;style=&#39;display:inline;border-collapse:collapse;&#39;&#34;
            )
            .set_caption(&#34;Feature Summary per Class&#34;)
            .set_properties(
                **{
                    &#34;border&#34;: &#34;1px solid #ddd&#34;,
                    &#34;padding&#34;: &#34;8px&#34;,
                    &#34;text-align&#34;: &#34;center&#34;,
                }
            )
        )

        display(
            HTML(
                &#34;&lt;p style=&#39;color: gray; margin-top:30px;&#39;&gt;Report generated with &#34;
                &#34;&lt;code&gt;GetInsights&lt;/code&gt; class. For detailed customization, extend &#34;
                &#34;&lt;code&gt;render_html_report&lt;/code&gt;.&lt;/p&gt;&#34;
            )
        )

    def viz_classifier_graphs(self, threshold_factor=1.0, top_k=5, save_path=None):
        &#34;&#34;&#34;
        Visualize all Dense layers in self.model.classifier as a single directed graph,
        connecting each Dense layer to the next.
        &#34;&#34;&#34;

        def get_top_k_edges(weights, src_prefix, dst_prefix, k):
            flat_weights = np.abs(weights.flatten())
            indices = np.argpartition(flat_weights, -k)[-k:]
            top_k_flat_indices = indices[np.argsort(-flat_weights[indices])]
            top_k_edges = []

            for flat_index in top_k_flat_indices:
                i, j = np.unravel_index(flat_index, weights.shape)
                top_k_edges.append((f&#34;{src_prefix}_{i}&#34;, f&#34;{dst_prefix}_{j}&#34;, weights[i, j]))
            return top_k_edges

        def add_dense_layer_edges(G, weights, layer_idx, threshold_factor, top_k):
            src_prefix = f&#34;L{layer_idx}&#34;
            dst_prefix = f&#34;L{layer_idx + 1}&#34;
            input_nodes = [f&#34;{src_prefix}_{i}&#34; for i in range(weights.shape[0])]
            output_nodes = [f&#34;{dst_prefix}_{j}&#34; for j in range(weights.shape[1])]

            G.add_nodes_from(input_nodes + output_nodes)

            abs_weights = np.abs(weights)
            threshold = threshold_factor * np.mean(abs_weights)
            top_k_edges = get_top_k_edges(weights, src_prefix, dst_prefix, top_k)
            top_k_set = set((u, v) for u, v, _ in top_k_edges)

            for i, src in enumerate(input_nodes):
                for j, dst in enumerate(output_nodes):
                    w = weights[i, j]
                    if abs(w) &gt; threshold:
                        G.add_edge(src, dst, weight=w, highlight=(src, dst) in top_k_set)

        def compute_layout(G):
            pos = {}
            layer_nodes = {}

            for node in G.nodes():
                layer_idx = int(node.split(&#34;_&#34;)[0][1:])
                layer_nodes.setdefault(layer_idx, []).append(node)

            for layer_idx, nodes in sorted(layer_nodes.items()):
                y_positions = np.linspace(1, -1, len(nodes))
                for y, node in zip(y_positions, nodes):
                    pos[node] = (layer_idx * 2, y)

            return pos

        def draw_graph(G, pos, title, save_path=None):
            weights = [abs(G[u][v][&#34;weight&#34;]) for u, v in G.edges()]
            if not weights:
                print(&#34;No edges to draw.&#34;)
                return

            norm = Normalize(vmin=min(weights), vmax=max(weights))
            cmap = cm.get_cmap(&#34;coolwarm&#34;)

            edge_colors = [cmap(norm(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]
            edge_widths = [1.0 + 2.0 * norm(abs(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]

            fig, ax = plt.subplots(figsize=(12, 8))

            nx.draw(
                G,
                pos,
                ax=ax,
                with_labels=True,
                node_color=&#34;lightgray&#34;,
                node_size=1000,
                font_size=8,
                edge_color=edge_colors,
                width=edge_widths,
                arrows=True,
            )

            ax.set_title(title, fontsize=14)

            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
            sm.set_array([])
            plt.colorbar(sm, ax=ax, orientation=&#34;vertical&#34;, label=&#34;Edge Weight&#34;)

            plt.tight_layout()
            if save_path:
                plt.savefig(save_path)
            plt.show()

        dense_layers = [
            layer
            for layer in self.model.classifier.layers
            if isinstance(layer, tf.keras.layers.Dense)
        ]

        if len(dense_layers) &lt; 1:
            print(&#34;No Dense layers found in classifier.&#34;)
            return

        G = nx.DiGraph()
        for idx, layer in enumerate(dense_layers):
            weights = layer.get_weights()[0]
            add_dense_layer_edges(G, weights, idx, threshold_factor, top_k)

        pos = compute_layout(G)
        draw_graph(G, pos, &#34;Classifier Dense Layers Graph&#34;, save_path)

    def viz_encoder_decoder_graphs(self, threshold_factor=1.0, top_k=5, save_path=None):
        &#34;&#34;&#34;
        Visualize Dense layers in self.model.encoder and self.model.decoder as directed graphs.
        &#34;&#34;&#34;

        def get_top_k_edges(weights, labels_src, labels_dst_prefix, k):
            flat_weights = np.abs(weights.flatten())
            indices = np.argpartition(flat_weights, -k)[-k:]
            top_k_flat_indices = indices[np.argsort(-flat_weights[indices])]
            top_k_edges = []
            for flat_index in top_k_flat_indices:
                i, j = np.unravel_index(flat_index, weights.shape)
                src_label = labels_src[i] if isinstance(labels_src, list) else f&#34;{labels_src}_{i}&#34;
                dst_label = f&#34;{labels_dst_prefix}_{j}&#34;
                top_k_edges.append((src_label, dst_label, weights[i, j]))
            return top_k_edges

        def add_layer_to_graph(
            G, weights, labels_src, labels_dst_prefix, x_offset, top_k_set, threshold
        ):
            output_nodes = [f&#34;{labels_dst_prefix}_{j}&#34; for j in range(weights.shape[1])]

            for node in labels_src + output_nodes:
                if node not in G:
                    G.add_node(node, x=x_offset if node in labels_src else x_offset + 1)

            for i, src in enumerate(labels_src):
                for j, dst in enumerate(output_nodes):
                    w = weights[i, j]
                    if abs(w) &gt; threshold:
                        G.add_edge(src, dst, weight=w, highlight=(src, dst) in top_k_set)
            return output_nodes

        def layout_graph(G):
            pos = {}
            layers = {}
            for node, data in G.nodes(data=True):
                x = data[&#34;x&#34;]
                layers.setdefault(x, []).append(node)

            for x in sorted(layers):
                nodes = layers[x]
                y_positions = np.linspace(1, -1, len(nodes))
                for y, node in zip(y_positions, nodes):
                    pos[node] = (x, y)
            return pos

        def draw_graph(G, title, ax):
            weights = [abs(G[u][v][&#34;weight&#34;]) for u, v in G.edges()]
            if not weights:
                return

            norm = Normalize(vmin=min(weights), vmax=max(weights))
            cmap = cm.get_cmap(&#34;coolwarm&#34;)

            edge_colors = [cmap(norm(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]
            edge_widths = [1.0 + 2.0 * norm(abs(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]

            pos = layout_graph(G)
            nx.draw(
                G,
                pos,
                ax=ax,
                with_labels=True,
                node_color=&#34;lightgray&#34;,
                node_size=1000,
                font_size=8,
                edge_color=edge_colors,
                width=edge_widths,
                arrows=True,
            )

            ax.set_title(title, fontsize=12)
            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
            sm.set_array([])
            plt.colorbar(sm, ax=ax, orientation=&#34;vertical&#34;, label=&#34;Edge Weight&#34;)

        def build_graph(layers, label_prefix, input_labels=None):
            G = nx.DiGraph()
            x_offset = 0
            prev_labels = input_labels or [
                f&#34;{label_prefix}0_{i}&#34; for i in range(layers[0].get_weights()[0].shape[0])
            ]

            for idx, layer in enumerate(layers):
                weights = layer.get_weights()[0]
                label = f&#34;{label_prefix}{idx+1}&#34;
                threshold = threshold_factor * np.mean(np.abs(weights))
                top_k_edges = get_top_k_edges(weights, prev_labels, label, top_k)
                top_k_set = set((src, dst) for src, dst, _ in top_k_edges)

                prev_labels = add_layer_to_graph(
                    G, weights, prev_labels, label, x_offset, top_k_set, threshold
                )
                x_offset += 2

            return G

        encoder_layers = [
            l for l in self.model.encoder.layers if isinstance(l, tf.keras.layers.Dense)
        ]
        decoder_layers = [
            l for l in self.model.decoder.layers if isinstance(l, tf.keras.layers.Dense)
        ]

        if not encoder_layers and not decoder_layers:
            print(&#34;No Dense layers found in encoder or decoder.&#34;)
            return

        n_graphs = int(bool(encoder_layers)) + int(bool(decoder_layers))
        fig, axes = plt.subplots(1, n_graphs, figsize=(7 * n_graphs, 6), squeeze=False)

        col = 0
        if encoder_layers:
            input_labels = (
                self.y_labels
                if self.y_labels
                and len(self.y_labels) == encoder_layers[0].get_weights()[0].shape[0]
                else None
            )
            encoder_graph = build_graph(encoder_layers, &#34;E&#34;, input_labels)
            draw_graph(encoder_graph, &#34;Encoder&#34;, axes[0][col])
            col += 1

        if decoder_layers:
            decoder_graph = build_graph(decoder_layers, &#34;D&#34;)
            draw_graph(decoder_graph, &#34;Decoder&#34;, axes[0][col])

        fig.suptitle(&#34;Encoder &amp; Decoder Dense Layer Graphs&#34;, fontsize=15)
        plt.tight_layout(rect=[0, 0, 1, 0.95])

        if save_path:
            plt.savefig(save_path)
        plt.show()

        if encoder_layers:
            weights = encoder_layers[0].get_weights()[0]
            importances = np.abs(weights).mean(axis=1)
            sorted_idx = np.argsort(-importances)
            xticks = [
                (
                    self.y_labels[i]
                    if self.y_labels and len(self.y_labels) == weights.shape[0]
                    else f&#34;Input_{i}&#34;
                )
                for i in sorted_idx
            ]

            plt.figure(figsize=(10, 4))
            plt.bar(range(len(importances)), importances[sorted_idx], color=&#34;skyblue&#34;)
            plt.xticks(range(len(importances)), xticks, rotation=45, ha=&#34;right&#34;)
            plt.title(&#34;Feature Importances (Encoder Input Layer)&#34;, fontsize=13)
            plt.ylabel(&#34;Mean |Weight|&#34;)
            plt.tight_layout()
            plt.show()

    def predictor_analyzer(
        self,
        frac: float = None,
        cmap: str = &#34;viridis&#34;,
        aspect: str = &#34;auto&#34;,
        highlight: bool = True,
        **kwargs,
    ) -&gt; None:
        &#34;&#34;&#34;
        Analyze the model&#39;s predictions and visualize data.

        Parameters
        ----------
        frac : `float`, optional
            Fraction of data to use for analysis (default is `None`).
        cmap : `str`, optional
            The colormap for visualization (default is `&#34;viridis&#34;`).
        aspect : `str`, optional
            Aspect ratio for the visualization (default is `&#34;auto&#34;`).
        highlight : `bool`, optional
            Whether to highlight the maximum weights (default is `True`).
        **kwargs : `dict`, optional
            Additional keyword arguments for customization.

        Returns
        -------
        `DataFrame` : The statistical summary of the input data.
        &#34;&#34;&#34;
        self._viz_weights(cmap=cmap, aspect=aspect, highlight=highlight, **kwargs)
        inputs = self.inputs.copy()
        inputs = self._prepare_inputs(inputs, frac)
        self.y_labels = kwargs.get(&#34;y_labels&#34;, None)
        encoded, reconstructed = self._encode_decode(inputs)
        self._visualize_data(inputs, reconstructed, cmap, aspect)
        self._prepare_data_for_analysis(inputs, reconstructed, encoded, self.y_labels)

        try:
            self._get_tsne_repr(inputs, frac)
            self._viz_tsne_repr(c=self.classification)

            self._viz_radviz(self.data, &#34;class&#34;, &#34;Radviz Visualization of Latent Space&#34;)
            self._viz_radviz(self.data_input, &#34;class&#34;, &#34;Radviz Visualization of Input Data&#34;)
        except ValueError:
            warnings.warn(
                &#34;Some functions or processes will not be executed for regression problems.&#34;,
                UserWarning,
            )

        return self._statistics(self.data_input)

    def _prepare_inputs(self, inputs: np.ndarray, frac: float) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Prepare the input data, possibly selecting a fraction of it.

        Parameters
        ----------
        inputs : `np.ndarray`
            The input data.
        frac : `float`
            Fraction of data to use.

        Returns
        -------
        `np.ndarray` : The prepared input data.
        &#34;&#34;&#34;
        if frac:
            n = int(frac * self.inputs.shape[0])
            indexes = np.random.choice(np.arange(inputs.shape[0]), n, replace=False)
            inputs = inputs[indexes]
        inputs[np.isnan(inputs)] = 0.0
        return inputs

    def _encode_decode(self, inputs: np.ndarray) -&gt; tuple:
        &#34;&#34;&#34;
        Perform encoding and decoding on the input data.

        Parameters
        ----------
        inputs : `np.ndarray`
            The input data.

        Returns
        -------
        `tuple` : The encoded and reconstructed data.
        &#34;&#34;&#34;
        try:
            mean, log_var = self.model.encoder(inputs)
            encoded = sampling(mean, log_var)
        except:
            encoded = self.model.encoder(inputs)
        reconstructed = self.model.decoder(encoded)
        return encoded, reconstructed

    def _visualize_data(
        self, inputs: np.ndarray, reconstructed: np.ndarray, cmap: str, aspect: str
    ) -&gt; None:
        &#34;&#34;&#34;
        Visualize the original data and the reconstructed data.

        Parameters
        ----------
        inputs : `np.ndarray`
            The input data.
        reconstructed : `np.ndarray`
            The reconstructed data.
        cmap : `str`
            The colormap for visualization.
        aspect : `str`
            Aspect ratio for the visualization.

        Returns
        -------
        `None`
        &#34;&#34;&#34;
        ax = plt.subplot(1, 2, 1)
        plt.imshow(inputs, cmap=cmap, aspect=aspect)
        plt.colorbar()
        plt.title(&#34;Original Data&#34;)

        plt.subplot(1, 2, 2, sharex=ax, sharey=ax)
        plt.imshow(reconstructed, cmap=cmap, aspect=aspect)
        plt.colorbar()
        plt.title(&#34;Decoder Layer Reconstruction&#34;)
        plt.show()

    def _prepare_data_for_analysis(
        self,
        inputs: np.ndarray,
        reconstructed: np.ndarray,
        encoded: np.ndarray,
        y_labels: List[str],
    ) -&gt; None:
        &#34;&#34;&#34;
        Prepare data for statistical analysis.

        Parameters
        ----------
        inputs : `np.ndarray`
            The input data.
        reconstructed : `np.ndarray`
            The reconstructed data.
        encoded : `np.ndarray`
            The encoded data.
        y_labels : `List[str]`
            The labels of features.

        Returns
        -------
        `None`
        &#34;&#34;&#34;
        self.classification = (
            self.model.classifier(tf.concat([reconstructed, encoded], axis=1))
            .numpy()
            .argmax(axis=1)
        )

        self.data = pd.DataFrame(encoded, columns=[f&#34;Feature {i}&#34; for i in range(encoded.shape[1])])
        self.data_input = pd.DataFrame(
            inputs,
            columns=(
                [f&#34;Feature {i}&#34; for i in range(inputs.shape[1])] if y_labels is None else y_labels
            ),
        )

        self.data[&#34;class&#34;] = self.classification
        self.data_input[&#34;class&#34;] = self.classification

    def _get_tsne_repr(self, inputs: np.ndarray = None, frac: float = None) -&gt; None:
        &#34;&#34;&#34;
        Perform t-SNE dimensionality reduction on the input data.

        Parameters
        ----------
        inputs : `np.ndarray`
            The input data.
        frac : `float`
            Fraction of data to use.

        Returns
        -------
        `None`
        &#34;&#34;&#34;
        if inputs is None:
            inputs = self.inputs.copy()
            if frac:
                n = int(frac * self.inputs.shape[0])
                indexes = np.random.choice(np.arange(inputs.shape[0]), n, replace=False)
                inputs = inputs[indexes]
            inputs[np.isnan(inputs)] = 0.0
        self.latent_representations = inputs @ self.encoder_weights

        tsne = TSNE(n_components=2)
        self.reduced_data_tsne = tsne.fit_transform(self.latent_representations)

    def _viz_tsne_repr(self, **kwargs) -&gt; None:
        &#34;&#34;&#34;
        Visualize the t-SNE representation of the latent space.

        Parameters
        ----------
        **kwargs : `dict`
            Additional keyword arguments for customization.

        Returns
        -------
        `None`
        &#34;&#34;&#34;
        c = kwargs.get(&#34;c&#34;, None)
        self.colors = (
            kwargs.get(&#34;colors&#34;, self.sorted_names[: len(np.unique(c))]) if c is not None else None
        )

        plt.scatter(
            self.reduced_data_tsne[:, 0],
            self.reduced_data_tsne[:, 1],
            cmap=matplotlib.colors.ListedColormap(self.colors) if c is not None else None,
            c=c,
        )

        if c is not None:
            cb = plt.colorbar()
            loc = np.arange(0, max(c), max(c) / float(len(self.colors)))
            cb.set_ticks(loc)
            cb.set_ticklabels(np.unique(c))

        plt.title(&#34;t-SNE Visualization of Latent Space&#34;)
        plt.xlabel(&#34;t-SNE 1&#34;)
        plt.ylabel(&#34;t-SNE 2&#34;)
        plt.show()

    def _viz_radviz(self, data: pd.DataFrame, color_column: str, title: str) -&gt; None:
        &#34;&#34;&#34;
        Visualize the data using RadViz.

        Parameters
        ----------
        data : `pd.DataFrame`
            The data to visualize.
        color_column : `str`
            The column to use for coloring.
        title : `str`
            The title of the plot.

        Returns
        -------
        `None`
        &#34;&#34;&#34;
        data_normalized = data.copy(deep=True)
        data_normalized.iloc[:, :-1] = (
            2.0
            * (data_normalized.iloc[:, :-1] - data_normalized.iloc[:, :-1].min())
            / (data_normalized.iloc[:, :-1].max() - data_normalized.iloc[:, :-1].min())
            - 1
        )
        data_normalized.dropna(axis=1, inplace=True)
        radviz(data_normalized, color_column, color=self.colors)
        plt.title(title)
        plt.show()

    def _viz_weights(
        self, cmap: str = &#34;viridis&#34;, aspect: str = &#34;auto&#34;, highlight: bool = True, **kwargs
    ) -&gt; None:
        &#34;&#34;&#34;
        Visualize the encoder layer weights of the model.

        Parameters
        ----------
        cmap : `str`, optional
            The colormap for visualization (default is `&#34;viridis&#34;`).
        aspect : `str`, optional
            Aspect ratio for the visualization (default is `&#34;auto&#34;`).
        highlight : `bool`, optional
            Whether to highlight the maximum weights (default is `True`).
        **kwargs : `dict`, optional
            Additional keyword arguments for customization.

        Returns
        -------
        `None`
        &#34;&#34;&#34;
        title = kwargs.get(&#34;title&#34;, &#34;Encoder Layer Weights (Dense Layer)&#34;)
        y_labels = kwargs.get(&#34;y_labels&#34;, None)
        cmap_highlight = kwargs.get(&#34;cmap_highlight&#34;, &#34;Pastel1&#34;)
        highlight_mask = np.zeros_like(self.encoder_weights, dtype=bool)

        plt.imshow(self.encoder_weights, cmap=cmap, aspect=aspect)
        plt.colorbar()
        plt.title(title)
        if y_labels is not None:
            plt.yticks(ticks=np.arange(self.encoder_weights.shape[0]), labels=y_labels)
        if highlight:
            for i, j in enumerate(self.encoder_weights.argmax(axis=1)):
                highlight_mask[i, j] = True
            plt.imshow(
                np.ma.masked_where(~highlight_mask, self.encoder_weights),
                cmap=cmap_highlight,
                alpha=0.5,
                aspect=aspect,
            )
        plt.show()

    def _statistics(self, data_input: DataFrame) -&gt; DataFrame:
        &#34;&#34;&#34;
        Compute statistical summaries of the input data.

        Parameters
        ----------
        data_input : `DataFrame`
            The data to compute statistics for.

        Returns
        -------
        `DataFrame` : The statistical summary of the input data.
        &#34;&#34;&#34;
        data = data_input.copy(deep=True)

        if not pd.api.types.is_string_dtype(data[&#34;class&#34;]):
            data[&#34;class&#34;] = data[&#34;class&#34;].astype(str)

        data.ffill(inplace=True)
        grouped_data = data.groupby(&#34;class&#34;)

        numerical_stats = grouped_data.agg([&#34;mean&#34;, &#34;min&#34;, &#34;max&#34;, &#34;std&#34;, &#34;median&#34;])
        numerical_stats.columns = [&#34;_&#34;.join(col).strip() for col in numerical_stats.columns.values]

        def get_mode(x):
            mode_series = x.mode()
            return mode_series.iloc[0] if not mode_series.empty else None

        mode_stats = grouped_data.apply(get_mode, include_groups=False)
        mode_stats.columns = [f&#34;{col}_mode&#34; for col in mode_stats.columns]
        combined_stats = pd.concat([numerical_stats, mode_stats], axis=1)

        return combined_stats.T</code></pre>
</details>
<div class="desc"><p>A class to analyze the output of a neural network model, including visualizations
of the weights, t-SNE representation, and feature statistics.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>AutoClassifier</code></dt>
<dd>The trained model to analyze.</dd>
<dt><strong><code>inputs</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The input data for analysis.</dd>
</dl>
<p>Initializes the GetInsights class.</p>
<h2 id="parameters_1">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>AutoClassifier</code></dt>
<dd>The trained model to analyze.</dd>
<dt><strong><code>inputs</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The input data for analysis.</dd>
</dl></div>
<h3>Methods</h3>
<dl>
<dt id="likelihood.models.deep.predictor.GetInsights.predictor_analyzer"><code class="name flex">
<span>def <span class="ident">predictor_analyzer</span></span>(<span>self,<br>frac:¬†float¬†=¬†None,<br>cmap:¬†str¬†=¬†'viridis',<br>aspect:¬†str¬†=¬†'auto',<br>highlight:¬†bool¬†=¬†True,<br>**kwargs) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predictor_analyzer(
    self,
    frac: float = None,
    cmap: str = &#34;viridis&#34;,
    aspect: str = &#34;auto&#34;,
    highlight: bool = True,
    **kwargs,
) -&gt; None:
    &#34;&#34;&#34;
    Analyze the model&#39;s predictions and visualize data.

    Parameters
    ----------
    frac : `float`, optional
        Fraction of data to use for analysis (default is `None`).
    cmap : `str`, optional
        The colormap for visualization (default is `&#34;viridis&#34;`).
    aspect : `str`, optional
        Aspect ratio for the visualization (default is `&#34;auto&#34;`).
    highlight : `bool`, optional
        Whether to highlight the maximum weights (default is `True`).
    **kwargs : `dict`, optional
        Additional keyword arguments for customization.

    Returns
    -------
    `DataFrame` : The statistical summary of the input data.
    &#34;&#34;&#34;
    self._viz_weights(cmap=cmap, aspect=aspect, highlight=highlight, **kwargs)
    inputs = self.inputs.copy()
    inputs = self._prepare_inputs(inputs, frac)
    self.y_labels = kwargs.get(&#34;y_labels&#34;, None)
    encoded, reconstructed = self._encode_decode(inputs)
    self._visualize_data(inputs, reconstructed, cmap, aspect)
    self._prepare_data_for_analysis(inputs, reconstructed, encoded, self.y_labels)

    try:
        self._get_tsne_repr(inputs, frac)
        self._viz_tsne_repr(c=self.classification)

        self._viz_radviz(self.data, &#34;class&#34;, &#34;Radviz Visualization of Latent Space&#34;)
        self._viz_radviz(self.data_input, &#34;class&#34;, &#34;Radviz Visualization of Input Data&#34;)
    except ValueError:
        warnings.warn(
            &#34;Some functions or processes will not be executed for regression problems.&#34;,
            UserWarning,
        )

    return self._statistics(self.data_input)</code></pre>
</details>
<div class="desc"><p>Analyze the model's predictions and visualize data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>frac</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Fraction of data to use for analysis (default is <code>None</code>).</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The colormap for visualization (default is <code>"viridis"</code>).</dd>
<dt><strong><code>aspect</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Aspect ratio for the visualization (default is <code>"auto"</code>).</dd>
<dt><strong><code>highlight</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to highlight the maximum weights (default is <code>True</code>).</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Additional keyword arguments for customization.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>DataFrame</code> : The statistical summary of the input data.</p></div>
</dd>
<dt id="likelihood.models.deep.predictor.GetInsights.render_html_report"><code class="name flex">
<span>def <span class="ident">render_html_report</span></span>(<span>self,<br>frac:¬†float¬†=¬†0.2,<br>top_k:¬†int¬†=¬†5,<br>threshold_factor:¬†float¬†=¬†1.0,<br>max_rows:¬†int¬†=¬†5,<br>**kwargs) ‚Äë>¬†None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def render_html_report(
    self,
    frac: float = 0.2,
    top_k: int = 5,
    threshold_factor: float = 1.0,
    max_rows: int = 5,
    **kwargs,
) -&gt; None:
    &#34;&#34;&#34;
    Generate and display an embedded HTML report in a Jupyter Notebook cell.
    &#34;&#34;&#34;
    display(HTML(&#34;&lt;h2 style=&#39;margin-top:20px;&#39;&gt;üìä Predictor Analysis&lt;/h2&gt;&#34;))
    display(
        HTML(
            &#34;&lt;p&gt;This section visualizes how the model predicts the data. &#34;
            &#34;You will see original inputs, reconstructed outputs, and analyses such as t-SNE &#34;
            &#34;that reduce dimensionality to visualize latent space clustering.&lt;/p&gt;&#34;
        )
    )
    stats_df = self.predictor_analyzer(frac=frac, **kwargs)

    display(HTML(&#34;&lt;h2 style=&#39;margin-top:30px;&#39;&gt;üîÅ Encoder-Decoder Graph&lt;/h2&gt;&#34;))
    display(
        HTML(
            &#34;&lt;p&gt;This visualization displays the connections between layers in the encoder and decoder. &#34;
            &#34;Edges with the strongest weights are highlighted to emphasize influential features &#34;
            &#34;in the model&#39;s transformation.&lt;/p&gt;&#34;
        )
    )
    if not self.model.encoder.name.startswith(&#34;vae&#34;):
        self.viz_encoder_decoder_graphs(threshold_factor=threshold_factor, top_k=top_k)

        display(HTML(&#34;&lt;h2 style=&#39;margin-top:30px;&#39;&gt;üß† Classifier Layer Graphs&lt;/h2&gt;&#34;))
        display(
            HTML(
                &#34;&lt;p&gt;This visualization shows how features propagate through each dense layer in the classifier. &#34;
                &#34;Only the strongest weighted connections are shown to highlight influential paths through the network.&lt;/p&gt;&#34;
            )
        )
    self.viz_classifier_graphs(threshold_factor=threshold_factor, top_k=top_k)

    display(HTML(&#34;&lt;h2 style=&#39;margin-top:30px;&#39;&gt;üìà Statistical Summary&lt;/h2&gt;&#34;))
    display(
        HTML(
            &#34;&lt;p&gt;This table summarizes feature statistics grouped by predicted classes, &#34;
            &#34;including means, standard deviations, and modes, providing insight into &#34;
            &#34;feature distributions across different classes.&lt;/p&gt;&#34;
        )
    )

    if max_rows is not None and max_rows &gt; 0:
        stats_to_display = stats_df.head(max_rows)
    else:
        stats_to_display = stats_df

    display(
        stats_to_display.style.set_table_attributes(
            &#34;style=&#39;display:inline;border-collapse:collapse;&#39;&#34;
        )
        .set_caption(&#34;Feature Summary per Class&#34;)
        .set_properties(
            **{
                &#34;border&#34;: &#34;1px solid #ddd&#34;,
                &#34;padding&#34;: &#34;8px&#34;,
                &#34;text-align&#34;: &#34;center&#34;,
            }
        )
    )

    display(
        HTML(
            &#34;&lt;p style=&#39;color: gray; margin-top:30px;&#39;&gt;Report generated with &#34;
            &#34;&lt;code&gt;GetInsights&lt;/code&gt; class. For detailed customization, extend &#34;
            &#34;&lt;code&gt;render_html_report&lt;/code&gt;.&lt;/p&gt;&#34;
        )
    )</code></pre>
</details>
<div class="desc"><p>Generate and display an embedded HTML report in a Jupyter Notebook cell.</p></div>
</dd>
<dt id="likelihood.models.deep.predictor.GetInsights.viz_classifier_graphs"><code class="name flex">
<span>def <span class="ident">viz_classifier_graphs</span></span>(<span>self, threshold_factor=1.0, top_k=5, save_path=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def viz_classifier_graphs(self, threshold_factor=1.0, top_k=5, save_path=None):
    &#34;&#34;&#34;
    Visualize all Dense layers in self.model.classifier as a single directed graph,
    connecting each Dense layer to the next.
    &#34;&#34;&#34;

    def get_top_k_edges(weights, src_prefix, dst_prefix, k):
        flat_weights = np.abs(weights.flatten())
        indices = np.argpartition(flat_weights, -k)[-k:]
        top_k_flat_indices = indices[np.argsort(-flat_weights[indices])]
        top_k_edges = []

        for flat_index in top_k_flat_indices:
            i, j = np.unravel_index(flat_index, weights.shape)
            top_k_edges.append((f&#34;{src_prefix}_{i}&#34;, f&#34;{dst_prefix}_{j}&#34;, weights[i, j]))
        return top_k_edges

    def add_dense_layer_edges(G, weights, layer_idx, threshold_factor, top_k):
        src_prefix = f&#34;L{layer_idx}&#34;
        dst_prefix = f&#34;L{layer_idx + 1}&#34;
        input_nodes = [f&#34;{src_prefix}_{i}&#34; for i in range(weights.shape[0])]
        output_nodes = [f&#34;{dst_prefix}_{j}&#34; for j in range(weights.shape[1])]

        G.add_nodes_from(input_nodes + output_nodes)

        abs_weights = np.abs(weights)
        threshold = threshold_factor * np.mean(abs_weights)
        top_k_edges = get_top_k_edges(weights, src_prefix, dst_prefix, top_k)
        top_k_set = set((u, v) for u, v, _ in top_k_edges)

        for i, src in enumerate(input_nodes):
            for j, dst in enumerate(output_nodes):
                w = weights[i, j]
                if abs(w) &gt; threshold:
                    G.add_edge(src, dst, weight=w, highlight=(src, dst) in top_k_set)

    def compute_layout(G):
        pos = {}
        layer_nodes = {}

        for node in G.nodes():
            layer_idx = int(node.split(&#34;_&#34;)[0][1:])
            layer_nodes.setdefault(layer_idx, []).append(node)

        for layer_idx, nodes in sorted(layer_nodes.items()):
            y_positions = np.linspace(1, -1, len(nodes))
            for y, node in zip(y_positions, nodes):
                pos[node] = (layer_idx * 2, y)

        return pos

    def draw_graph(G, pos, title, save_path=None):
        weights = [abs(G[u][v][&#34;weight&#34;]) for u, v in G.edges()]
        if not weights:
            print(&#34;No edges to draw.&#34;)
            return

        norm = Normalize(vmin=min(weights), vmax=max(weights))
        cmap = cm.get_cmap(&#34;coolwarm&#34;)

        edge_colors = [cmap(norm(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]
        edge_widths = [1.0 + 2.0 * norm(abs(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]

        fig, ax = plt.subplots(figsize=(12, 8))

        nx.draw(
            G,
            pos,
            ax=ax,
            with_labels=True,
            node_color=&#34;lightgray&#34;,
            node_size=1000,
            font_size=8,
            edge_color=edge_colors,
            width=edge_widths,
            arrows=True,
        )

        ax.set_title(title, fontsize=14)

        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
        sm.set_array([])
        plt.colorbar(sm, ax=ax, orientation=&#34;vertical&#34;, label=&#34;Edge Weight&#34;)

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path)
        plt.show()

    dense_layers = [
        layer
        for layer in self.model.classifier.layers
        if isinstance(layer, tf.keras.layers.Dense)
    ]

    if len(dense_layers) &lt; 1:
        print(&#34;No Dense layers found in classifier.&#34;)
        return

    G = nx.DiGraph()
    for idx, layer in enumerate(dense_layers):
        weights = layer.get_weights()[0]
        add_dense_layer_edges(G, weights, idx, threshold_factor, top_k)

    pos = compute_layout(G)
    draw_graph(G, pos, &#34;Classifier Dense Layers Graph&#34;, save_path)</code></pre>
</details>
<div class="desc"><p>Visualize all Dense layers in self.model.classifier as a single directed graph,
connecting each Dense layer to the next.</p></div>
</dd>
<dt id="likelihood.models.deep.predictor.GetInsights.viz_encoder_decoder_graphs"><code class="name flex">
<span>def <span class="ident">viz_encoder_decoder_graphs</span></span>(<span>self, threshold_factor=1.0, top_k=5, save_path=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def viz_encoder_decoder_graphs(self, threshold_factor=1.0, top_k=5, save_path=None):
    &#34;&#34;&#34;
    Visualize Dense layers in self.model.encoder and self.model.decoder as directed graphs.
    &#34;&#34;&#34;

    def get_top_k_edges(weights, labels_src, labels_dst_prefix, k):
        flat_weights = np.abs(weights.flatten())
        indices = np.argpartition(flat_weights, -k)[-k:]
        top_k_flat_indices = indices[np.argsort(-flat_weights[indices])]
        top_k_edges = []
        for flat_index in top_k_flat_indices:
            i, j = np.unravel_index(flat_index, weights.shape)
            src_label = labels_src[i] if isinstance(labels_src, list) else f&#34;{labels_src}_{i}&#34;
            dst_label = f&#34;{labels_dst_prefix}_{j}&#34;
            top_k_edges.append((src_label, dst_label, weights[i, j]))
        return top_k_edges

    def add_layer_to_graph(
        G, weights, labels_src, labels_dst_prefix, x_offset, top_k_set, threshold
    ):
        output_nodes = [f&#34;{labels_dst_prefix}_{j}&#34; for j in range(weights.shape[1])]

        for node in labels_src + output_nodes:
            if node not in G:
                G.add_node(node, x=x_offset if node in labels_src else x_offset + 1)

        for i, src in enumerate(labels_src):
            for j, dst in enumerate(output_nodes):
                w = weights[i, j]
                if abs(w) &gt; threshold:
                    G.add_edge(src, dst, weight=w, highlight=(src, dst) in top_k_set)
        return output_nodes

    def layout_graph(G):
        pos = {}
        layers = {}
        for node, data in G.nodes(data=True):
            x = data[&#34;x&#34;]
            layers.setdefault(x, []).append(node)

        for x in sorted(layers):
            nodes = layers[x]
            y_positions = np.linspace(1, -1, len(nodes))
            for y, node in zip(y_positions, nodes):
                pos[node] = (x, y)
        return pos

    def draw_graph(G, title, ax):
        weights = [abs(G[u][v][&#34;weight&#34;]) for u, v in G.edges()]
        if not weights:
            return

        norm = Normalize(vmin=min(weights), vmax=max(weights))
        cmap = cm.get_cmap(&#34;coolwarm&#34;)

        edge_colors = [cmap(norm(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]
        edge_widths = [1.0 + 2.0 * norm(abs(G[u][v][&#34;weight&#34;])) for u, v in G.edges()]

        pos = layout_graph(G)
        nx.draw(
            G,
            pos,
            ax=ax,
            with_labels=True,
            node_color=&#34;lightgray&#34;,
            node_size=1000,
            font_size=8,
            edge_color=edge_colors,
            width=edge_widths,
            arrows=True,
        )

        ax.set_title(title, fontsize=12)
        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
        sm.set_array([])
        plt.colorbar(sm, ax=ax, orientation=&#34;vertical&#34;, label=&#34;Edge Weight&#34;)

    def build_graph(layers, label_prefix, input_labels=None):
        G = nx.DiGraph()
        x_offset = 0
        prev_labels = input_labels or [
            f&#34;{label_prefix}0_{i}&#34; for i in range(layers[0].get_weights()[0].shape[0])
        ]

        for idx, layer in enumerate(layers):
            weights = layer.get_weights()[0]
            label = f&#34;{label_prefix}{idx+1}&#34;
            threshold = threshold_factor * np.mean(np.abs(weights))
            top_k_edges = get_top_k_edges(weights, prev_labels, label, top_k)
            top_k_set = set((src, dst) for src, dst, _ in top_k_edges)

            prev_labels = add_layer_to_graph(
                G, weights, prev_labels, label, x_offset, top_k_set, threshold
            )
            x_offset += 2

        return G

    encoder_layers = [
        l for l in self.model.encoder.layers if isinstance(l, tf.keras.layers.Dense)
    ]
    decoder_layers = [
        l for l in self.model.decoder.layers if isinstance(l, tf.keras.layers.Dense)
    ]

    if not encoder_layers and not decoder_layers:
        print(&#34;No Dense layers found in encoder or decoder.&#34;)
        return

    n_graphs = int(bool(encoder_layers)) + int(bool(decoder_layers))
    fig, axes = plt.subplots(1, n_graphs, figsize=(7 * n_graphs, 6), squeeze=False)

    col = 0
    if encoder_layers:
        input_labels = (
            self.y_labels
            if self.y_labels
            and len(self.y_labels) == encoder_layers[0].get_weights()[0].shape[0]
            else None
        )
        encoder_graph = build_graph(encoder_layers, &#34;E&#34;, input_labels)
        draw_graph(encoder_graph, &#34;Encoder&#34;, axes[0][col])
        col += 1

    if decoder_layers:
        decoder_graph = build_graph(decoder_layers, &#34;D&#34;)
        draw_graph(decoder_graph, &#34;Decoder&#34;, axes[0][col])

    fig.suptitle(&#34;Encoder &amp; Decoder Dense Layer Graphs&#34;, fontsize=15)
    plt.tight_layout(rect=[0, 0, 1, 0.95])

    if save_path:
        plt.savefig(save_path)
    plt.show()

    if encoder_layers:
        weights = encoder_layers[0].get_weights()[0]
        importances = np.abs(weights).mean(axis=1)
        sorted_idx = np.argsort(-importances)
        xticks = [
            (
                self.y_labels[i]
                if self.y_labels and len(self.y_labels) == weights.shape[0]
                else f&#34;Input_{i}&#34;
            )
            for i in sorted_idx
        ]

        plt.figure(figsize=(10, 4))
        plt.bar(range(len(importances)), importances[sorted_idx], color=&#34;skyblue&#34;)
        plt.xticks(range(len(importances)), xticks, rotation=45, ha=&#34;right&#34;)
        plt.title(&#34;Feature Importances (Encoder Input Layer)&#34;, fontsize=13)
        plt.ylabel(&#34;Mean |Weight|&#34;)
        plt.tight_layout()
        plt.show()</code></pre>
</details>
<div class="desc"><p>Visualize Dense layers in self.model.encoder and self.model.decoder as directed graphs.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="likelihood.models.deep" href="index.html">likelihood.models.deep</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="likelihood.models.deep.predictor.GetInsights" href="#likelihood.models.deep.predictor.GetInsights">GetInsights</a></code></h4>
<ul class="">
<li><code><a title="likelihood.models.deep.predictor.GetInsights.predictor_analyzer" href="#likelihood.models.deep.predictor.GetInsights.predictor_analyzer">predictor_analyzer</a></code></li>
<li><code><a title="likelihood.models.deep.predictor.GetInsights.render_html_report" href="#likelihood.models.deep.predictor.GetInsights.render_html_report">render_html_report</a></code></li>
<li><code><a title="likelihood.models.deep.predictor.GetInsights.viz_classifier_graphs" href="#likelihood.models.deep.predictor.GetInsights.viz_classifier_graphs">viz_classifier_graphs</a></code></li>
<li><code><a title="likelihood.models.deep.predictor.GetInsights.viz_encoder_decoder_graphs" href="#likelihood.models.deep.predictor.GetInsights.viz_encoder_decoder_graphs">viz_encoder_decoder_graphs</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
