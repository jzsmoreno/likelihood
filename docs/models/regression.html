<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>likelihood.models.regression API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>likelihood.models.regression</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="likelihood.models.regression.AbstractArima"><code class="flex name class">
<span>class <span class="ident">AbstractArima</span></span>
<span>(</span><span>datapoints: numpy.ndarray,<br>n_steps: int = 0,<br>noise: float = 0,<br>tol: float = 0.0001)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"><p>A class that implements the auto-regressive arima (1, 0, 0) model</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="likelihood.models.utils.FeaturesArima" href="utils.html#likelihood.models.utils.FeaturesArima">FeaturesArima</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="likelihood.models.regression.Arima" href="#likelihood.models.regression.Arima">Arima</a></li>
<li><a title="likelihood.models.regression.FourierRegression" href="#likelihood.models.regression.FourierRegression">FourierRegression</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="likelihood.models.regression.AbstractArima.datapoints"><code class="name">var <span class="ident">datapoints</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.mov"><code class="name">var <span class="ident">mov</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.n_steps"><code class="name">var <span class="ident">n_steps</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.noise"><code class="name">var <span class="ident">noise</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.nwalkers"><code class="name">var <span class="ident">nwalkers</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.p"><code class="name">var <span class="ident">p</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.q"><code class="name">var <span class="ident">q</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.theta_trained"><code class="name">var <span class="ident">theta_trained</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.tol"><code class="name">var <span class="ident">tol</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractArima(FeaturesArima):
    &#34;&#34;&#34;A class that implements the auto-regressive arima (1, 0, 0) model&#34;&#34;&#34;

    __slots__ = [
        &#34;datapoints&#34;,
        &#34;n_steps&#34;,
        &#34;noise&#34;,
        &#34;p&#34;,
        &#34;q&#34;,
        &#34;tol&#34;,
        &#34;nwalkers&#34;,
        &#34;mov&#34;,
        &#34;theta_trained&#34;,
    ]

    def __init__(self, datapoints: ndarray, n_steps: int = 0, noise: float = 0, tol: float = 1e-4):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        self.p = datapoints.shape[0]
        self.q = 0
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode=True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        return super().forward(datapoints, theta, mode, noise)

    def xvec(self, datapoints: ndarray, n_steps: int = 0):
        datapoints = self.datapoints
        self.n_steps = n_steps

        return datapoints[n_steps:]

    def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
        datapoints = self.datapoints
        xvec = self.xvec

        self.nwalkers = nwalkers
        self.mov = mov

        assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

        model = self.model

        n = self.p + self.q

        theta = np.random.rand(n)

        x_vec = xvec(datapoints)

        if weights:
            par, error = walkers(
                nwalkers,
                x_vec,
                datapoints,
                model,
                theta=self.theta_trained,
                mov=mov,
                tol=self.tol,
                figname=None,
            )
        else:
            par, error = walkers(
                nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
            )

        index = np.where(error == np.min(error))[0][0]
        trained = np.array(par[index])

        self.theta_trained = trained

    def predict(self, n_steps: int = 0):
        self.n_steps = n_steps

        datapoints = self.datapoints
        model = self.model
        theta_trained = self.theta_trained

        y_pred = model(datapoints, theta_trained)

        for i in range(n_steps):
            self.datapoints = y_pred[i:]
            y_new = model(datapoints, theta_trained, mode=False)
            y_pred = y_pred.tolist()
            y_pred.append(y_new)
            y_pred = np.array(y_pred)

        return np.array(y_pred)

    def save_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
            pickle.dump(self.theta_trained, file)

    def load_model(self, name: str = &#34;model&#34;):
        with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
            self.theta_trained = pickle.load(file)

    def eval(self, y_val: ndarray, y_pred: ndarray):
        rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
        square_error = np.sqrt((y_pred - y_val) ** 2)
        accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
        accuracy /= np.sum(square_error)
        print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
        print(&#34;RMSE: {:.4f}&#34;.format(rmse))

    def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
        plt.figure()
        n = self.n_steps
        y_mean = np.mean(y_pred, axis=0)
        y_std = np.std(y_pred, axis=0)
        if ci &lt; 0.95:
            Z = (ci / 0.90) * 1.64
        else:
            Z = (ci / 0.95) * 1.96

        plt.plot(y_pred, label=&#34;Predicted&#34;)
        plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
        plt.fill_between(
            (range(y_pred.shape[0]))[-n:],
            (y_pred - Z * y_std)[-n:],
            (y_pred + Z * y_std)[-n:],
            alpha=0.2,
        )
        plt.xlabel(&#34;Time steps&#34;)
        plt.ylabel(&#34;y&#34;)
        plt.legend()
        print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
        if mode:
            plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
        plt.show()

    def summary(self):
        print(&#34;\nSummary:&#34;)
        print(&#34;-----------------------&#34;)
        print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
        print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
        print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="likelihood.models.regression.AbstractArima.eval"><code class="name flex">
<span>def <span class="ident">eval</span></span>(<span>self, y_val: numpy.ndarray, y_pred: numpy.ndarray)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval(self, y_val: ndarray, y_pred: ndarray):
    rmse = np.sqrt(np.mean((y_pred - y_val) ** 2))
    square_error = np.sqrt((y_pred - y_val) ** 2)
    accuracy = np.sum(square_error[np.where(square_error &lt; rmse)])
    accuracy /= np.sum(square_error)
    print(&#34;Accuracy: {:.4f}&#34;.format(accuracy))
    print(&#34;RMSE: {:.4f}&#34;.format(rmse))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>self, name: str = 'model')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_model(self, name: str = &#34;model&#34;):
    with open(name + &#34;.pkl&#34;, &#34;rb&#34;) as file:
        self.theta_trained = pickle.load(file)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.model"><code class="name flex">
<span>def <span class="ident">model</span></span>(<span>self, datapoints: numpy.ndarray, theta: list, mode=True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def model(self, datapoints: ndarray, theta: list, mode=True):
    datapoints = self.datapoints
    noise = self.noise
    self.theta_trained = theta

    return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.plot_pred"><code class="name flex">
<span>def <span class="ident">plot_pred</span></span>(<span>self,<br>y_real: numpy.ndarray,<br>y_pred: numpy.ndarray,<br>ci: float = 0.9,<br>mode: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_pred(self, y_real: ndarray, y_pred: ndarray, ci: float = 0.90, mode: bool = True):
    plt.figure()
    n = self.n_steps
    y_mean = np.mean(y_pred, axis=0)
    y_std = np.std(y_pred, axis=0)
    if ci &lt; 0.95:
        Z = (ci / 0.90) * 1.64
    else:
        Z = (ci / 0.95) * 1.96

    plt.plot(y_pred, label=&#34;Predicted&#34;)
    plt.plot(y_real, &#34;.--&#34;, label=&#34;Real&#34;, alpha=0.5)
    plt.fill_between(
        (range(y_pred.shape[0]))[-n:],
        (y_pred - Z * y_std)[-n:],
        (y_pred + Z * y_std)[-n:],
        alpha=0.2,
    )
    plt.xlabel(&#34;Time steps&#34;)
    plt.ylabel(&#34;y&#34;)
    plt.legend()
    print(&#34;Confidence Interval: {:.4f}&#34;.format(Z * y_std))
    if mode:
        plt.savefig(&#34;pred_&#34; + str(n) + &#34;.png&#34;, dpi=300)
    plt.show()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, n_steps: int = 0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, n_steps: int = 0):
    self.n_steps = n_steps

    datapoints = self.datapoints
    model = self.model
    theta_trained = self.theta_trained

    y_pred = model(datapoints, theta_trained)

    for i in range(n_steps):
        self.datapoints = y_pred[i:]
        y_new = model(datapoints, theta_trained, mode=False)
        y_pred = y_pred.tolist()
        y_pred.append(y_new)
        y_pred = np.array(y_pred)

    return np.array(y_pred)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.save_model"><code class="name flex">
<span>def <span class="ident">save_model</span></span>(<span>self, name: str = 'model')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_model(self, name: str = &#34;model&#34;):
    with open(name + &#34;.pkl&#34;, &#34;wb&#34;) as file:
        pickle.dump(self.theta_trained, file)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.summary"><code class="name flex">
<span>def <span class="ident">summary</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summary(self):
    print(&#34;\nSummary:&#34;)
    print(&#34;-----------------------&#34;)
    print(&#34;Lenght of theta: {}&#34;.format(len(self.theta_trained)))
    print(&#34;Mean of theta: {:.4f}&#34;.format(np.mean(self.theta_trained)))
    print(&#34;-----------------------&#34;)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, nwalkers: int = 1, mov: int = 200, weights: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, nwalkers: int = 1, mov: int = 200, weights: bool = False):
    datapoints = self.datapoints
    xvec = self.xvec

    self.nwalkers = nwalkers
    self.mov = mov

    assert self.nwalkers &lt;= self.mov, &#34;n_walkers must be less or equal than mov&#34;

    model = self.model

    n = self.p + self.q

    theta = np.random.rand(n)

    x_vec = xvec(datapoints)

    if weights:
        par, error = walkers(
            nwalkers,
            x_vec,
            datapoints,
            model,
            theta=self.theta_trained,
            mov=mov,
            tol=self.tol,
            figname=None,
        )
    else:
        par, error = walkers(
            nwalkers, x_vec, datapoints, model, theta, mov=mov, tol=self.tol, figname=None
        )

    index = np.where(error == np.min(error))[0][0]
    trained = np.array(par[index])

    self.theta_trained = trained</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.AbstractArima.xvec"><code class="name flex">
<span>def <span class="ident">xvec</span></span>(<span>self, datapoints: numpy.ndarray, n_steps: int = 0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def xvec(self, datapoints: ndarray, n_steps: int = 0):
    datapoints = self.datapoints
    self.n_steps = n_steps

    return datapoints[n_steps:]</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="likelihood.models.regression.Arima"><code class="flex name class">
<span>class <span class="ident">Arima</span></span>
<span>(</span><span>datapoints: numpy.ndarray,<br>p: float = 1,<br>d: int = 0,<br>q: float = 0,<br>n_steps: int = 0,<br>noise: float = 0,<br>tol: float = 1e-05)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"><p>A class that implements the (p, d, q) arima model</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>datapoints</code></strong> :&ensp;<code>np.array</code></dt>
<dd>A set of points to train the arima model.</dd>
<dt><strong><code>p</code></strong> :&ensp;<code>float</code></dt>
<dd>Is the number of auto-regressive terms (ratio). By default it is set to <code>1</code></dd>
<dt><strong><code>d</code></strong> :&ensp;<code>int</code></dt>
<dd>Is known as the degree of differencing. By default it is set to <code>0</code></dd>
<dt><strong><code>q</code></strong> :&ensp;<code>float</code></dt>
<dd>Is the number of forecast errors in the model (ratio). By default it is set to <code>0</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y_pred</code></strong> :&ensp;<code>np.array</code></dt>
<dd>It is the number of predicted points. It is necessary
to apply predict(n_steps) followed by train()</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="likelihood.models.regression.AbstractArima" href="#likelihood.models.regression.AbstractArima">AbstractArima</a></li>
<li><a title="likelihood.models.utils.FeaturesArima" href="utils.html#likelihood.models.utils.FeaturesArima">FeaturesArima</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="likelihood.models.regression.Arima.d"><code class="name">var <span class="ident">d</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.Arima.datapoints"><code class="name">var <span class="ident">datapoints</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.Arima.n_steps"><code class="name">var <span class="ident">n_steps</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.Arima.noise"><code class="name">var <span class="ident">noise</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.Arima.p"><code class="name">var <span class="ident">p</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.Arima.q"><code class="name">var <span class="ident">q</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.Arima.theta_trained"><code class="name">var <span class="ident">theta_trained</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.Arima.tol"><code class="name">var <span class="ident">tol</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Arima(AbstractArima):
    &#34;&#34;&#34;A class that implements the (p, d, q) arima model

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    p : float
        Is the number of auto-regressive terms (ratio). By default it is set to `1`

    d : int
        Is known as the degree of differencing. By default it is set to `0`

    q : float
        Is the number of forecast errors in the model (ratio). By default it is set to `0`

    Returns
    -------

    y_pred : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by train()
    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints&#34;, &#34;n_steps&#34;, &#34;noise&#34;, &#34;p&#34;, &#34;d&#34;, &#34;q&#34;, &#34;tol&#34;, &#34;theta_trained&#34;]

    def __init__(
        self,
        datapoints: ndarray,
        p: float = 1,
        d: int = 0,
        q: float = 0,
        n_steps: int = 0,
        noise: float = 0,
        tol: float = 1e-5,
    ):
        self.datapoints = datapoints
        self.n_steps = n_steps
        self.noise = noise
        assert p &gt; 0 and p &lt;= 1, &#34;p must be less than 1 but greater than 0&#34;
        self.p = int(p * len(datapoints))
        assert d &gt;= 0 and d &lt;= 1, &#34;p must be less than 1 but greater than or equal to 0&#34;
        self.d = d
        self.q = int(q * len(datapoints))
        self.tol = tol

    def model(self, datapoints: ndarray, theta: list, mode: bool = True):
        datapoints = self.datapoints
        noise = self.noise
        self.theta_trained = theta

        assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

        if self.d != 0 or self.q != 0:
            if self.d != 0:
                y_sum = super().integrated(datapoints)
            else:
                y_sum = datapoints

            y_sum_regr = y_sum[-self.p :]
            y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
            if self.q != 0:
                y_sum_average = super().average(y_sum[-self.q :])
                y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
                if mode:
                    y_vec = y_regr_vec
                    for i in reversed(range(y_average_vec.shape[0])):
                        y_vec[i] += y_average_vec[i]
                else:
                    y_vec = y_regr_vec + y_average_vec
            else:
                y_vec = y_regr_vec

            return y_vec
        else:
            return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="likelihood.models.regression.Arima.model"><code class="name flex">
<span>def <span class="ident">model</span></span>(<span>self, datapoints: numpy.ndarray, theta: list, mode: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def model(self, datapoints: ndarray, theta: list, mode: bool = True):
    datapoints = self.datapoints
    noise = self.noise
    self.theta_trained = theta

    assert type(self.d) == int, &#34;d must be 0, 1 or 2&#34;

    if self.d != 0 or self.q != 0:
        if self.d != 0:
            y_sum = super().integrated(datapoints)
        else:
            y_sum = datapoints

        y_sum_regr = y_sum[-self.p :]
        y_regr_vec = super().forward(y_sum_regr, theta[0 : self.p], mode, 0)
        if self.q != 0:
            y_sum_average = super().average(y_sum[-self.q :])
            y_average_vec = super().forward(y_sum_average, theta[-self.q :], mode, 0)
            if mode:
                y_vec = y_regr_vec
                for i in reversed(range(y_average_vec.shape[0])):
                    y_vec[i] += y_average_vec[i]
            else:
                y_vec = y_regr_vec + y_average_vec
        else:
            y_vec = y_regr_vec

        return y_vec
    else:
        return super().forward(datapoints, theta, mode, noise)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="likelihood.models.regression.FourierRegression"><code class="flex name class">
<span>class <span class="ident">FourierRegression</span></span>
<span>(</span><span>datapoints: numpy.ndarray, n_steps: int = 0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"><p>A class that implements the arima model with FFT noise filtering</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>datapoints</code></strong> :&ensp;<code>np.array</code></dt>
<dd>A set of points to train the arima model.</dd>
<dt><strong><code>n_steps</code></strong> :&ensp;<code>int</code></dt>
<dd>Is the number of points that in predict(n_steps)
stage will estimate foward. By default it is set to <code>0</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>new_datapoints</code></strong> :&ensp;<code>np.array</code></dt>
<dd>It is the number of predicted points. It is necessary
to apply predict(n_steps) followed by fit()</dd>
</dl></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="likelihood.models.regression.AbstractArima" href="#likelihood.models.regression.AbstractArima">AbstractArima</a></li>
<li><a title="likelihood.models.utils.FeaturesArima" href="utils.html#likelihood.models.utils.FeaturesArima">FeaturesArima</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="likelihood.models.regression.FourierRegression.datapoints_"><code class="name">var <span class="ident">datapoints_</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.mode"><code class="name">var <span class="ident">mode</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.mov"><code class="name">var <span class="ident">mov</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.n_steps"><code class="name">var <span class="ident">n_steps</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.n_walkers"><code class="name">var <span class="ident">n_walkers</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.name"><code class="name">var <span class="ident">name</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.sigma"><code class="name">var <span class="ident">sigma</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FourierRegression(AbstractArima):
    &#34;&#34;&#34;A class that implements the arima model with FFT noise filtering

    Parameters
    ----------

    datapoints : np.array
        A set of points to train the arima model.

    n_steps : int
        Is the number of points that in predict(n_steps)
        stage will estimate foward. By default it is set to `0`.

    Returns
    -------

    new_datapoints : np.array
        It is the number of predicted points. It is necessary
        to apply predict(n_steps) followed by fit()

    &#34;&#34;&#34;

    __slots__ = [&#34;datapoints_&#34;, &#34;n_steps&#34;, &#34;sigma&#34;, &#34;mode&#34;, &#34;mov&#34;, &#34;n_walkers&#34;, &#34;name&#34;]

    def __init__(self, datapoints: ndarray, n_steps: int = 0):
        self.datapoints_ = datapoints
        self.n_steps = n_steps

    def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
        self.sigma = sigma
        self.mode = mode
        self.mov = mov

        datapoints = self.datapoints_
        self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)

    def predict(
        self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
    ):
        self.n_steps = n_steps
        self.n_walkers = n_walkers
        self.name = name
        mov = self.mov

        assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

        new_datapoints = []
        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().train(n_walkers, mov)
            if save:
                super().save_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints

    def load_predict(self, name: str = &#34;fourier_model&#34;):
        n_steps = self.n_steps

        new_datapoints = []

        for i in range(self.datapoints_.shape[0]):
            super().__init__(self.datapoints_[i, :])
            super().load_model(str(i) + &#34;_&#34; + name)
            y_pred_ = super().predict(n_steps)
            new_datapoints.append(y_pred_)

        new_datapoints = np.array(new_datapoints)
        new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

        return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="likelihood.models.regression.FourierRegression.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, sigma: int = 0, mov: int = 200, mode: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, sigma: int = 0, mov: int = 200, mode: bool = False):
    self.sigma = sigma
    self.mode = mode
    self.mov = mov

    datapoints = self.datapoints_
    self.datapoints_, _ = fft_denoise(datapoints, sigma, mode)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.load_predict"><code class="name flex">
<span>def <span class="ident">load_predict</span></span>(<span>self, name: str = 'fourier_model')</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_predict(self, name: str = &#34;fourier_model&#34;):
    n_steps = self.n_steps

    new_datapoints = []

    for i in range(self.datapoints_.shape[0]):
        super().__init__(self.datapoints_[i, :])
        super().load_model(str(i) + &#34;_&#34; + name)
        y_pred_ = super().predict(n_steps)
        new_datapoints.append(y_pred_)

    new_datapoints = np.array(new_datapoints)
    new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

    return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="likelihood.models.regression.FourierRegression.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self,<br>n_steps: int = 0,<br>n_walkers: int = 1,<br>name: str = 'fourier_model',<br>save: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(
    self, n_steps: int = 0, n_walkers: int = 1, name: str = &#34;fourier_model&#34;, save: bool = True
):
    self.n_steps = n_steps
    self.n_walkers = n_walkers
    self.name = name
    mov = self.mov

    assert self.n_walkers &lt;= mov, &#34;n_walkers must be less or equal than mov&#34;

    new_datapoints = []
    for i in range(self.datapoints_.shape[0]):
        super().__init__(self.datapoints_[i, :])
        super().train(n_walkers, mov)
        if save:
            super().save_model(str(i) + &#34;_&#34; + name)
        y_pred_ = super().predict(n_steps)
        new_datapoints.append(y_pred_)

    new_datapoints = np.array(new_datapoints)
    new_datapoints = np.reshape(new_datapoints, (len(new_datapoints), -1))

    return new_datapoints</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="likelihood.models" href="index.html">likelihood.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="likelihood.models.regression.AbstractArima" href="#likelihood.models.regression.AbstractArima">AbstractArima</a></code></h4>
<ul class="two-column">
<li><code><a title="likelihood.models.regression.AbstractArima.datapoints" href="#likelihood.models.regression.AbstractArima.datapoints">datapoints</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.eval" href="#likelihood.models.regression.AbstractArima.eval">eval</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.load_model" href="#likelihood.models.regression.AbstractArima.load_model">load_model</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.model" href="#likelihood.models.regression.AbstractArima.model">model</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.mov" href="#likelihood.models.regression.AbstractArima.mov">mov</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.n_steps" href="#likelihood.models.regression.AbstractArima.n_steps">n_steps</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.noise" href="#likelihood.models.regression.AbstractArima.noise">noise</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.nwalkers" href="#likelihood.models.regression.AbstractArima.nwalkers">nwalkers</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.p" href="#likelihood.models.regression.AbstractArima.p">p</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.plot_pred" href="#likelihood.models.regression.AbstractArima.plot_pred">plot_pred</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.predict" href="#likelihood.models.regression.AbstractArima.predict">predict</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.q" href="#likelihood.models.regression.AbstractArima.q">q</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.save_model" href="#likelihood.models.regression.AbstractArima.save_model">save_model</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.summary" href="#likelihood.models.regression.AbstractArima.summary">summary</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.theta_trained" href="#likelihood.models.regression.AbstractArima.theta_trained">theta_trained</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.tol" href="#likelihood.models.regression.AbstractArima.tol">tol</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.train" href="#likelihood.models.regression.AbstractArima.train">train</a></code></li>
<li><code><a title="likelihood.models.regression.AbstractArima.xvec" href="#likelihood.models.regression.AbstractArima.xvec">xvec</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="likelihood.models.regression.Arima" href="#likelihood.models.regression.Arima">Arima</a></code></h4>
<ul class="two-column">
<li><code><a title="likelihood.models.regression.Arima.d" href="#likelihood.models.regression.Arima.d">d</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.datapoints" href="#likelihood.models.regression.Arima.datapoints">datapoints</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.model" href="#likelihood.models.regression.Arima.model">model</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.n_steps" href="#likelihood.models.regression.Arima.n_steps">n_steps</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.noise" href="#likelihood.models.regression.Arima.noise">noise</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.p" href="#likelihood.models.regression.Arima.p">p</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.q" href="#likelihood.models.regression.Arima.q">q</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.theta_trained" href="#likelihood.models.regression.Arima.theta_trained">theta_trained</a></code></li>
<li><code><a title="likelihood.models.regression.Arima.tol" href="#likelihood.models.regression.Arima.tol">tol</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="likelihood.models.regression.FourierRegression" href="#likelihood.models.regression.FourierRegression">FourierRegression</a></code></h4>
<ul class="two-column">
<li><code><a title="likelihood.models.regression.FourierRegression.datapoints_" href="#likelihood.models.regression.FourierRegression.datapoints_">datapoints_</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.fit" href="#likelihood.models.regression.FourierRegression.fit">fit</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.load_predict" href="#likelihood.models.regression.FourierRegression.load_predict">load_predict</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.mode" href="#likelihood.models.regression.FourierRegression.mode">mode</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.mov" href="#likelihood.models.regression.FourierRegression.mov">mov</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.n_steps" href="#likelihood.models.regression.FourierRegression.n_steps">n_steps</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.n_walkers" href="#likelihood.models.regression.FourierRegression.n_walkers">n_walkers</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.name" href="#likelihood.models.regression.FourierRegression.name">name</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.predict" href="#likelihood.models.regression.FourierRegression.predict">predict</a></code></li>
<li><code><a title="likelihood.models.regression.FourierRegression.sigma" href="#likelihood.models.regression.FourierRegression.sigma">sigma</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
